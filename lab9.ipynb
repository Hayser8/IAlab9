{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f261ac8",
   "metadata": {},
   "source": [
    "## **Laboratorio 9**\n",
    "## **Julio Garc√≠a Salas - 22076**\n",
    "## **Sof√≠a Garc√≠a - 22210**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14cbba4",
   "metadata": {},
   "source": [
    "# Modelos de Markov y Hidden Markov Models (HMM)\n",
    "\n",
    "## 1. Diferencia entre Modelos de Markov y Hidden Markov Models\n",
    "\n",
    "Un **Modelo de Markov (Markov Chain)** es un modelo probabil√≠stico que describe una secuencia de posibles eventos en los que la probabilidad de cada evento depende √∫nicamente del estado alcanzado en el evento anterior. Es decir, el proceso tiene la propiedad de **Markov**, tambi√©n conocida como **memoria limitada**.\n",
    "\n",
    "- En un Modelo de Markov cl√°sico, los **estados son observables**.\n",
    "- Se describe con una matriz de transici√≥n $A$ entre estados.\n",
    "\n",
    "Un **Modelo Oculto de Markov (Hidden Markov Model, HMM)** es una extensi√≥n del modelo de Markov donde el **estado real no es observable directamente** (es \"oculto\"), pero se puede inferir a partir de **observaciones** que dependen probabil√≠sticamente de los estados ocultos.\n",
    "\n",
    "- En un HMM, se tiene:\n",
    "  - Una secuencia de **estados ocultos** $q_1, q_2, ..., q_T$\n",
    "  - Una secuencia de **observaciones** $o_1, o_2, ..., o_T$\n",
    "  - Probabilidades de emisi√≥n $B$ que definen la probabilidad de observar $o_t$ dado el estado oculto $q_t$\n",
    "\n",
    "## 2. ¬øQu√© son los factorial HMM?\n",
    "\n",
    "Los **Factorial Hidden Markov Models (FHMM)** son una generalizaci√≥n de los HMM tradicionales. En lugar de tener una √∫nica cadena de estados ocultos, un FHMM utiliza **varias cadenas ocultas que evolucionan en paralelo** y que juntas determinan la distribuci√≥n de las observaciones.\n",
    "\n",
    "- Cada cadena de estados ocultos sigue un modelo de Markov independiente.\n",
    "- Las observaciones se generan a partir de la **combinaci√≥n de m√∫ltiples cadenas ocultas**.\n",
    "\n",
    "Esto permite modelar **dependencias m√°s complejas** entre los estados y las observaciones. Son √∫tiles en contextos donde m√∫ltiples factores ocultos influyen en los datos observados (por ejemplo, reconocimiento de actividad humana, bioinform√°tica, etc.).\n",
    "\n",
    "## 3. Algoritmo Forward-Backward para HMM\n",
    "\n",
    "El algoritmo **Forward-Backward** es una t√©cnica de inferencia utilizada en HMMs para **calcular la probabilidad de una secuencia de observaciones** y para inferir la **probabilidad posterior de los estados ocultos** en cada tiempo dado.\n",
    "\n",
    "Se divide en dos fases:\n",
    "\n",
    "- **Forward ($\\alpha$) paso**: calcula de manera recursiva la probabilidad de la secuencia observada hasta el tiempo $t$ y de estar en un estado $i$ en ese momento:\n",
    "  \n",
    "  $$\n",
    "  \\alpha_t(i) = P(o_1, o_2, ..., o_t, q_t = i \\mid \\lambda)\n",
    "  $$\n",
    "\n",
    "- **Backward ($\\beta$) paso**: calcula la probabilidad de observar el resto de la secuencia desde $t+1$ en adelante, dado que el sistema est√° en el estado $i$ en el tiempo $t$:\n",
    "\n",
    "  $$\n",
    "  \\beta_t(i) = P(o_{t+1}, o_{t+2}, ..., o_T \\mid q_t = i, \\lambda)\n",
    "  $$\n",
    "\n",
    "- Finalmente, la probabilidad posterior de estar en un estado $i$ en el tiempo $t$ dado la secuencia completa de observaciones es:\n",
    "\n",
    "  $$\n",
    "  \\gamma_t(i) = \\frac{\\alpha_t(i) \\cdot \\beta_t(i)}{\\sum_{j=1}^N \\alpha_t(j) \\cdot \\beta_t(j)}\n",
    "  $$\n",
    "\n",
    "## 4. ¬øPor qu√© es necesario el paso Backward?\n",
    "\n",
    "El paso **Backward** permite incorporar la informaci√≥n **futura** (las observaciones posteriores al tiempo $t$) para estimar correctamente la probabilidad de que el sistema haya estado en un determinado estado en ese tiempo.\n",
    "\n",
    "### Ejemplo:\n",
    "\n",
    "Supongamos que tenemos una observaci√≥n inesperada al final de la secuencia que dif√≠cilmente pudo haber ocurrido en algunos estados anteriores. Sin el paso **Backward**, el algoritmo no tendr√≠a forma de ajustar las probabilidades anteriores con base en esa nueva informaci√≥n.\n",
    "\n",
    "- Por ejemplo, si en el tiempo $t=1$ se considera probable estar en el estado $S_1$, pero en el tiempo $t=3$ se observa un evento muy improbable desde $S_1$, el paso backward puede ajustar hacia abajo la probabilidad de $S_1$ en $t=1$.\n",
    "\n",
    "Esto se debe a que los **HMM son modelos generativos de toda la secuencia**, y no solo del presente. Sin el paso backward, solo se tendr√≠a una visi√≥n parcial (solo hacia adelante) y se perder√≠a contexto importante que afecta la inferencia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40594a9f",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4ef0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class HMM:\n",
    "    def __init__(self, states, observations, initial_prob, transition_prob, emission_prob):\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.initial_prob = initial_prob\n",
    "        self.transition_prob = transition_prob\n",
    "        self.emission_prob = emission_prob\n",
    "\n",
    "    def generate_sequence(self, length):\n",
    "        sequence = []\n",
    "        current_state = random.choices(self.states, weights=[self.initial_prob[s] for s in self.states])[0]\n",
    "        for _ in range(length):\n",
    "            obs = random.choices(self.observations, weights=[self.emission_prob[current_state][o] for o in self.observations])[0]\n",
    "            sequence.append(obs)\n",
    "            current_state = random.choices(self.states, weights=[self.transition_prob[current_state][s] for s in self.states])[0]\n",
    "        return sequence\n",
    "\n",
    "    def forward(self, observations):\n",
    "        alpha = []\n",
    "        for t, obs in enumerate(observations):\n",
    "            alpha_t = {}\n",
    "            for state in self.states:\n",
    "                if t == 0:\n",
    "                    alpha_t[state] = self.initial_prob[state] * self.emission_prob[state][obs]\n",
    "                else:\n",
    "                    alpha_t[state] = sum(\n",
    "                        alpha[t-1][prev_state] * self.transition_prob[prev_state][state] for prev_state in self.states\n",
    "                    ) * self.emission_prob[state][obs]\n",
    "            alpha.append(alpha_t)\n",
    "        return alpha\n",
    "\n",
    "    def backward(self, observations):\n",
    "        beta = [{} for _ in observations]\n",
    "        T = len(observations)\n",
    "        for state in self.states:\n",
    "            beta[T-1][state] = 1\n",
    "        for t in reversed(range(T-1)):\n",
    "            for state in self.states:\n",
    "                beta[t][state] = sum(\n",
    "                    self.transition_prob[state][next_state] *\n",
    "                    self.emission_prob[next_state][observations[t+1]] *\n",
    "                    beta[t+1][next_state]\n",
    "                    for next_state in self.states\n",
    "                )\n",
    "        return beta\n",
    "\n",
    "    def compute_state_probabilities(self, observations):\n",
    "        alpha = self.forward(observations)\n",
    "        beta = self.backward(observations)\n",
    "        gamma = []\n",
    "        for t in range(len(observations)):\n",
    "            prob_sum = sum(alpha[t][s] * beta[t][s] for s in self.states)\n",
    "            gamma_t = {s: (alpha[t][s] * beta[t][s]) / prob_sum for s in self.states}\n",
    "            gamma.append(gamma_t)\n",
    "        return gamma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aa4d52",
   "metadata": {},
   "source": [
    "## **Implementaci√≥n de la clase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0ee3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencia Generada: ['Sunny', 'Rainy', 'Sunny', 'Rainy', 'Rainy']\n",
      "Probabilidades Forward:\n",
      "[{'Sunny': 0.4, 'Rainy': 0.15}, {'Sunny': 0.30400000000000005, 'Rainy': 0.051000000000000004}, {'Sunny': 0.05272000000000002, 'Rainy': 0.06398000000000001}, {'Sunny': 0.013553600000000006, 'Rainy': 0.0342524}]\n",
      "Probabilidades Backward:\n",
      "[{'Sunny': 0.08956000000000001, 'Rainy': 0.07988}, {'Sunny': 0.11800000000000001, 'Rainy': 0.23399999999999999}, {'Sunny': 0.30000000000000004, 'Rainy': 0.5}, {'Sunny': 1, 'Rainy': 1}]\n",
      "Probabilidades de Estados:\n",
      "[{'Sunny': 0.7493620047692758, 'Rainy': 0.25063799523072416}, {'Sunny': 0.7503660628373008, 'Rainy': 0.24963393716269922}, {'Sunny': 0.33083713341421583, 'Rainy': 0.669162866585784}, {'Sunny': 0.283512529807974, 'Rainy': 0.7164874701920261}]\n"
     ]
    }
   ],
   "source": [
    "states = ['Sunny', 'Rainy']\n",
    "observations = ['Sunny', 'Sunny', 'Rainy', 'Rainy']\n",
    "initial_prob = {'Sunny': 0.5, 'Rainy': 0.5}\n",
    "transition_prob = {\n",
    "    'Sunny': {'Sunny': 0.8, 'Rainy': 0.2},\n",
    "    'Rainy': {'Sunny': 0.4, 'Rainy': 0.6}\n",
    "}\n",
    "emission_prob = {\n",
    "    'Sunny': {'Sunny': 0.8, 'Rainy': 0.2},\n",
    "    'Rainy': {'Sunny': 0.3, 'Rainy': 0.7}\n",
    "}\n",
    "\n",
    "hmm = HMM(states, ['Sunny', 'Rainy'], initial_prob, transition_prob, emission_prob)\n",
    "\n",
    "# 3. Secuencia generada (opcional)\n",
    "obs_sequence = hmm.generate_sequence(5)\n",
    "print(\"Secuencia Generada:\", obs_sequence)\n",
    "\n",
    "# 4. Probabilidades Forward\n",
    "forward_probs = hmm.forward(observations)\n",
    "print(\"Probabilidades Forward:\")\n",
    "print(forward_probs)\n",
    "\n",
    "# 5. Probabilidades Backward\n",
    "backward_probs = hmm.backward(observations)\n",
    "print(\"Probabilidades Backward:\")\n",
    "print(backward_probs)\n",
    "\n",
    "# 6. Probabilidades combinadas (estado)\n",
    "state_probs = hmm.compute_state_probabilities(observations)\n",
    "print(\"Probabilidades de Estados:\")\n",
    "print(state_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe488d6",
   "metadata": {},
   "source": [
    "# üîç An√°lisis de Secuencia y Probabilidades en un Modelo Oculto de Markov (HMM)\n",
    "\n",
    "---\n",
    "\n",
    "## üìå Secuencia Generada\n",
    "\n",
    "La secuencia de observaciones generada por el modelo fue:\n",
    "```python\n",
    "['Sunny', 'Rainy', 'Sunny', 'Sunny', 'Rainy']\n",
    "```\n",
    "Esta secuencia ser√° utilizada para el an√°lisis de probabilidades a lo largo del tiempo.\n",
    "\n",
    "---\n",
    "\n",
    "## üìà 1. Probabilidades Forward (`Œ±`)\n",
    "\n",
    "Las probabilidades forward representan la **probabilidad conjunta de observar la secuencia hasta el tiempo $t$ y estar en un estado espec√≠fico**:\n",
    "```python\n",
    "[ {'Sunny': 0.4, 'Rainy': 0.15}, {'Sunny': 0.304, 'Rainy': 0.051}, {'Sunny': 0.05272, 'Rainy': 0.06398}, {'Sunny': 0.0135536, 'Rainy': 0.0342524} ]\n",
    "```\n",
    "\n",
    "### üìù Observaciones:\n",
    "- En el tiempo $t=0$, hay una mayor probabilidad de estar en **Sunny** (0.4 vs. 0.15), influenciado por la alta probabilidad de emisi√≥n de 'Sunny' en el estado 'Sunny'.\n",
    "- En $t=1$, la probabilidad en 'Sunny' sigue dominando (0.304), pero comienza a ceder terreno frente a 'Rainy'.\n",
    "- A partir de $t=2$ y $t=3$, la probabilidad de estar en 'Rainy' aumenta, lo cual refleja el cambio de tendencia en las observaciones hacia valores de 'Rainy'.\n",
    "\n",
    "---\n",
    "\n",
    "## üìâ 2. Probabilidades Backward (`Œ≤`)\n",
    "\n",
    "Las probabilidades backward representan la **probabilidad de observar la secuencia restante desde $t+1$ hasta el final**, dado que el sistema est√° en un estado particular en el tiempo $t$:\n",
    "```python\n",
    "[ {'Sunny': 0.08956, 'Rainy': 0.07988}, {'Sunny': 0.118, 'Rainy': 0.234}, {'Sunny': 0.3, 'Rainy': 0.5}, {'Sunny': 1, 'Rainy': 1} ]\n",
    "```\n",
    "\n",
    "### üìù Observaciones:\n",
    "- En $t=3$ (√∫ltimo paso analizado), las probabilidades backward valen 1, ya que no hay eventos futuros a considerar.\n",
    "- En $t=1$ y $t=2$, la probabilidad de continuar en la secuencia es m√°s alta desde el estado 'Rainy', dado que las observaciones siguientes son mayormente 'Rainy'.\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ 3. Probabilidades Posteriores de Estado (`Œ≥`)\n",
    "\n",
    "Estas probabilidades combinan la informaci√≥n de `Œ±` y `Œ≤` para estimar la **probabilidad de que el sistema est√© en un estado dado en el tiempo $t$, considerando toda la secuencia observada**:\n",
    "```python\n",
    "[ {'Sunny': 0.74936, 'Rainy': 0.25064}, {'Sunny': 0.75037, 'Rainy': 0.24963}, {'Sunny': 0.33084, 'Rainy': 0.66916}, {'Sunny': 0.28351, 'Rainy': 0.71649} ]\n",
    "```\n",
    "\n",
    "\n",
    "### üìù Observaciones:\n",
    "- En los primeros dos pasos ($t=0$ y $t=1$), el sistema tiene una fuerte inclinaci√≥n hacia el estado 'Sunny', consistente con las observaciones iniciales.\n",
    "- A partir de $t=2$, el modelo actualiza sus creencias y empieza a favorecer 'Rainy' como estado oculto, especialmente debido a la secuencia de observaciones 'Rainy' consecutivas.\n",
    "- Esto refleja una propiedad clave de los HMMs: **la capacidad de reconsiderar hip√≥tesis previas en funci√≥n de nueva evidencia futura**.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Conclusiones\n",
    "\n",
    "- El modelo HMM ajusta sus estimaciones de estado oculto conforme avanza la secuencia observada.\n",
    "- La combinaci√≥n del algoritmo Forward y Backward permite capturar no solo la historia pasada, sino tambi√©n la influencia del futuro sobre el presente.\n",
    "- En este ejemplo, la transici√≥n progresiva de 'Sunny' a 'Rainy' como estado m√°s probable muestra un comportamiento consistente con la evidencia proporcionada por la secuencia observada.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
